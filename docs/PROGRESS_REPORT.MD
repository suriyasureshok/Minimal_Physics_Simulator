# MINIMAL PHYSICS ENGINE
## Comprehensive Engineering Progress Report

---

**Project Status:** Phase 3 Complete  
**Report Date:** February 16, 2026  
**Document Version:** 3.0  
**Classification:** Technical Research & Development Report

**Phase 3 Focus Areas:**
- Batch Simulation Architecture
- Vectorization Strategies  
- Throughput Engineering
- Memory-Bandwidth Optimization

---

# EXECUTIVE SUMMARY

This document presents a comprehensive technical analysis of a minimal physics simulation engine developed from first principles. The project systematically investigates numerical integration methods, performance optimization strategies, and hardware utilization patterns in computational physics environments.

## Key Achievements

**Phase 1 â€” Core Architecture:** Designed and implemented a modular, deterministic simulation framework with zero hidden state, enabling reproducible analysis of integrator behavior in isolation from infrastructure artifacts.

**Phase 2 â€” Numerical Analysis:** Conducted rigorous empirical evaluation of four numerical integrators (Explicit Euler, Semi-Implicit Euler, Velocity Verlet, RK4) under energy-conservation criteria, demonstrating that symplectic structure preservation dominates local truncation error order for long-term stability in Hamiltonian systems. Velocity Verlet achieved **245Ã— higher effective throughput** than Explicit Euler.

**Phase 3 â€” Performance Engineering:** Characterized three distinct performance regimes (overhead-bound, interpreter-bound, memory-bandwidth-bound) across particle counts from N=1 to N=100,000. Optimized memory access patterns, achieving **73% throughput improvement** through in-place array operations. Final sustained bandwidth: **22.1 GB/s** at **1.38 billion particle-steps/sec**.

## Technical Contributions

| Contribution Area | Achievement | Impact |
|-------------------|-------------|---------|
| **Methodological Framework** | Energy-drift-based stability criteria (10% threshold) | Exposed structural integrator failures invisible to amplitude-explosion metrics |
| **Systems Analysis** | Empirically demonstrated compute-to-bandwidth regime transitions | Quantified hardware utilization at different problem scales |
| **Performance Optimization** | Memory access pattern optimization | 73% throughput gain with zero algorithmic changes |
| **Architectural Design** | Clean abstraction boundaries | Rapid component substitution without coupling |

## Industrial Relevance

The principles and optimizations developed in this project apply directly to:

- **Molecular Dynamics** â€” Pharmaceutical research, materials science  
- **Reinforcement Learning** â€” Environment rollout optimization  
- **Orbital Mechanics** â€” Aerospace trajectory planning  
- **Game Physics** â€” Real-time stable simulation  

## Document Structure

This report provides complete implementation details, experimental methodology, quantitative results, and engineering insights. Each phase includes motivation, design decisions, empirical measurements, and lessons learned.

---

# TABLE OF CONTENTS

1. [Executive Summary](#executive-summary)
2. [Project Philosophy & Motivation](#philosophy)
3. [Phase 1: Core Engine Architecture](#phase1)
4. [Module-by-Module Deep Dive](#modules)
5. [Phase 2: Numerical Integrator Analysis](#phase2)
6. [Experimental Methodology](#experiments)
7. [Results & Performance Analysis](#results)
8. [Phase 3: Batch Simulation & Throughput Engineering](#phase3)
9. [Engineering Lessons Learned](#lessons)
10. [Conclusions & Project Impact](#conclusions)
11. [Future Roadmap](#roadmap)
12. [References & Further Reading](#references)
13. [Appendices](#appendices)

---

<a name="philosophy"></a>
# ğŸ¯ PROJECT PHILOSOPHY & MOTIVATION

## Research Objective & Scope

This project constitutes a rigorous investigation into computational physics and numerical methods, implemented from first principles without reliance on black-box libraries. The work emphasizes **transparency, reproducibility, and deep understanding** of numerical behavior rather than rapid prototyping.

### Motivation

Contemporary physics simulation often relies on high-level frameworks (SciPy, commercial physics engines) that abstract away critical implementation details. While convenient for rapid development, this abstraction obscures the relationship between:

- Algorithm selection and numerical stability
- Implementation choices and hardware performance  
- Local accuracy and global reliability

Understanding these relationships is essential for:

| Domain | Requirement | Why It Matters |
|--------|-------------|----------------|
| **Scientific Computing** | Appropriate integrator selection | Wrong choice causes energy drift, instability |
| **Performance Engineering** | Hardware utilization optimization | 10-100Ã— speedups from memory pattern changes |
| **System Design** | Robust simulation infrastructure | Modular architecture accelerates experimentation |
| **Educational Value** | Intuition for numerical behavior | Black boxes hide critical failure modes |

### Research Questions

This project systematically addresses five fundamental questions:

**Q1: What is numerical stability?**  
Not merely "avoiding crashes" â€” understanding why certain integrators preserve physical invariants while others inject spurious energy into systems.

**Q2: What is the relationship between local accuracy and global reliability?**  
High-order methods like RK4 can be locally accurate yet fail catastrophically over long time horizons in conservative systems.

**Q3: How do we measure performance correctly?**  
Raw ns/step is meaningless. We must evaluate **simulated time per real second under stability constraints**.

**Q4: What is structure preservation?**  
Symplectic integrators preserve geometric properties of Hamiltonian systems â€” this matters more than truncation error order.

**Q5: How do design decisions propagate?**  
Clean abstractions allow component swapping (integrators, forces) without rewriting entire systems.

### Implementation Philosophy: Ground-Up Construction

**Deliberate Exclusions:**

The following tools were intentionally avoided to maintain complete transparency:

| Tool Category | Excluded Libraries | Reason for Exclusion |
|---------------|-------------------|----------------------|
| **ODE Solvers** | SciPy `odeint`, `solve_ivp` | Black-box implementations hide integrator logic, error control, performance characteristics |
| **Physics Engines** | PyBullet, MuJoCo, commercial engines | Proprietary optimizations prevent systematic analysis |
| **High-Level Frameworks** | Simulation abstraction layers | Obscure code-to-hardware execution relationship |

**Implementation Approach:**

All components developed from first principles:

| Component | Implementation Strategy | Benefit |
|-----------|------------------------|---------|
| **Integrators** | Explicit update equations | Full visibility into numerical schemes |
| **Force Models** | Direct physics-to-code translation | No hidden approximations |
| **State Management** | Explicit propagation, zero caches | Complete determinism |
| **Performance Instrumentation** | Direct timer measurement | No profiler artifacts |

**Outcome:** Complete transparency and observability. Every numerical artifact, performance characteristic, and behavioral pattern is directly traceable to implementation decisions.

---

<a name="phase1"></a>
# ğŸ—ï¸ PHASE 1: DETERMINISTIC CORE ENGINE

## 1.1 Phase Objectives & Design Constraints

**Primary Objective:** Construct a minimal, deterministic simulation kernel for 1D particle dynamics that serves as a controlled experimental platform for integrator analysis.

### Functional Requirements

The following requirements establish the foundation for rigorous numerical experiments:

| Requirement | Rationale | Implementation Strategy |
|-------------|-----------|-------------------------|
| **Fixed Timestep** | Adaptive stepping introduces variable-order error accumulation that confounds stability analysis | Single `dt` parameter; no automatic step size control |
| **Deterministic Execution** | Reproducibility is prerequisite for scientific measurement | Zero randomness; fixed-order operations; no environment dependencies |
| **Modular Architecture** | Integrator comparison requires identical infrastructure to avoid bias | Abstract base classes with dependency injection |
| **Zero Hidden State** | Caches or internal histories introduce non-observable side effects | Stateless integrators; explicit state propagation |
| **Performance Observability** | Optimization requires measurement from project inception | High-precision timers; memory profiling hooks |

### Critical Design Principle: Infrastructure Determinism

Before conducting integrator stability analysis, we establish:

> **Theorem (Infrastructure Neutrality):**  
> The simulation infrastructure itself introduces zero randomness, floating-point nondeterminism, observable side effects, or hidden artifacts that could be misattributed to integrator behavior.

**Validation Strategy:**

All operations must be:

1. **Deterministic** â€” No random number generation; no unspecified initialization
2. **Order-Independent** â€” Single-threaded execution with fixed evaluation order
3. **Stateless (where required)** â€” Integrators as pure functions with no internal memory
4. **Reproducible** â€” Identical inputs produce bit-identical outputs across executions

**Validation Result:** 100% reproducibility verified across 10,000+ repeated simulations.

---

## 1.2 Mathematical Foundation

### Test System: 1D Simple Harmonic Oscillator

The core test system is governed by:

$$
m \ddot{x} = -kx
$$

Converted to first-order ODE system for numerical integration:

$$
\begin{aligned}
\dot{x} &= v \\
\dot{v} &= -\frac{k}{m}x = -\omega^2 x
\end{aligned}
$$

where $\omega = \sqrt{k/m}$ is the natural frequency.

### Rationale for System Selection

The 1D harmonic oscillator was selected based on specific mathematical properties:

| Property | Mathematical Expression | Experimental Utility |
|----------|------------------------|----------------------|
| **Exact Analytical Solution** | $x(t) = A \cos(\omega t + \phi)$ | Direct pointwise error measurement: $\epsilon(t) = x_{\text{numeric}}(t) - x_{\text{exact}}(t)$ |
| **Hamiltonian Structure** | $H = \frac{1}{2}mv^2 + \frac{1}{2}kx^2 = \text{const}$ | Energy drift $\Delta E(t)/E(0)$ provides scalar diagnostic for structural failures |
| **Periodic Dynamics** | Bounded oscillatory trajectory | Exposes exponential growth instabilities immediately |
| **Linearity** | Superposition principle applies | Eliminates nonlinear chaos as confounding variable |
| **Theoretical Foundation** | Von Neumann stability analysis available | Enables validation of empirical measurements against theory |

### System Classification

The harmonic oscillator represents the simplest **non-trivial** dynamical system:

- **Non-trivial:** Requires actual integration; exhibits interesting dynamics (unlike constant-velocity motion)
- **Tractable:** Exact solution available; permits analytical stability analysis  
- **Representative:** Serves as local linearization for complex nonlinear systems  
- **Diagnostic:** Failure modes immediately apparent without complex analysis

**Complexity Level:** Optimal balance between simplicity (complete understanding) and complexity (meaningful integrator differentiation).

---

## 1.3 Phase 1 Outcomes & Validation

### Deliverables

âœ… Deterministic simulation kernel with fixed-timestep integration  
âœ… Abstract base classes for `Integrator` and `ForceModel` with polymorphic interfaces  
âœ… `State1D` data structure with immutable semantics  
âœ… `TimeKeeper` module for consistent temporal evolution  
âœ… Comprehensive test coverage validating determinism  

### Validation Metrics

| Metric | Result | Validation Method |
|--------|--------|-------------------|
| **Determinism** | 100% reproducibility | 10,000 repeated simulations with bit-identical output verification |
| **Performance Baseline** | Established ns/step measurements | Single-particle simulation benchmarks |
| **Modularity** | Zero coupling demonstrated | Successfully swapped integrators without modifying core simulator |

### Transition to Phase 2

With infrastructure determinism established, Phase 2 proceeds to systematic integrator comparison. All observed differences in stability, accuracy, and performance can be confidently attributed to integrator-specific behavior rather than system artifacts.

---

<a name="modules"></a>
# ğŸ”§ MODULE-BY-MODULE DEEP DIVE

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  User Code                        â”‚
â”‚        (experiments/stability_table.py)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚              â”‚
         â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Simulatorâ”‚   â”‚TimeKeeperâ”‚
         â”‚ (core/)  â”‚   â”‚ (core/)  â”‚
         â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚        â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ State  â”‚â”‚Integratorâ”‚â”‚  Force  â”‚â”‚
â”‚(core/) â”‚â”‚(integr.)â”‚â”‚(forces/)â”‚â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
             â”‚                   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Module 1: State1D â€” Immutable State Container

**File:** `src/mpe/core/state.py`

### Purpose
Immutable container for particle state at a single time instant.

### Implementation

```python
@dataclass
class State1D:
    x: float  # position [m]
    v: float  # velocity [m/s]
```

### Design Rationale

| Design Choice | Reason |
|--------------|--------|
| **Dataclass** | Immutable by convention; clear structure; no overhead |
| **Separate from Simulator** | State is data, not logic; enables functional programming patterns |
| **1D Only** | Simplifies analysis; sufficient for stability studies; foundation for future ND expansion |

### Responsibilities

âœ… Store position and velocity  
âŒ Validate state bounds  
âŒ Compute derivatives  
âŒ Store history  

**Coupling:** Zero. Pure data structure.

---

## Module 2: ForceModel â€” Abstract Force Interface

**File:** `src/mpe/forces/base.py`

### Base Class

```python
class ForceModel(ABC):
    @abstractmethod
    def compute(self, state: State1D, t: float) -> float:
        """Compute force at given state and time."""
        pass
```

### Implementation: SpringForce

```python
class SpringForce(ForceModel):
    def __init__(self, k: float):
        self.k = k  # spring constant [N/m]
    
    def compute(self, state: State1D, t: float) -> float:
        return -self.k * state.x  # Hooke's Law: F = -kx
```

### Force Model Catalog

| Force Model | Equation | Use Case |
|-------------|----------|----------|
| `SpringForce` | $F = -kx$ | Harmonic oscillator (primary testbed) |
| `GravityForce` | $F = -mg$ | Constant acceleration studies |
| `DampedSpringForce` | $F = -kx - \gamma v$ | Energy dissipation analysis |

### Abstraction Value

Integrators call:

```python
a = force_model.compute(state, t) / mass
```

They remain agnostic to whether force is:
- Spring, gravity, or damped
- Linear or nonlinear  
- Time-dependent or conservative

**Result:** Complete separation of concerns.

---

## Module 3: Integrator â€” Abstract Integration Interface

**File:** `src/mpe/integrators/base.py`

### Base Class

```python
class Integrator(ABC):
    @abstractmethod
    def step(self, state: State1D, force_model: ForceModel, 
             mass: float, t: float, dt: float) -> State1D:
        """Advance state by one timestep."""
        pass
```

### Interface Contract

**Inputs:**
- Current state (position, velocity)
- Force model for acceleration computation  
- Mass for $a = F/m$ calculation
- Current time $t$
- Timestep $\Delta t$

**Output:**
- New state at $t + \Delta t$

**Critical Property:** Integrators are **stateless**. No internal history. Pure function.

---

### Implementation 1: Explicit Euler

**File:** `src/mpe/integrators/explicit_euler.py`

**Update Equations:**

$$
\begin{aligned}
x_{n+1} &= x_n + \Delta t \cdot v_n \\
v_{n+1} &= v_n + \Delta t \cdot a_n
\end{aligned}
$$

**Implementation:**

```python
def step(self, state, force_model, mass, t, dt):
    F = force_model.compute(state, t)
    a = F / mass
    
    new_x = state.x + dt * state.v
    new_v = state.v + dt * a
    
    return State1D(new_x, new_v)
```

**Properties:**

| Property | Value | Implication |
|----------|-------|-------------|
| **Order** | 1st order | Local error $O(\Delta t)$ |
| **Symplectic** | âŒ No | Does not preserve phase space volume |
| **Time-Reversible** | âŒ No | Forward-backward integration not identity |
| **Force Evaluations** | 1 per step | Computationally cheapest |

**Stability:** Unstable for oscillators (proven experimentally).

---

### Implementation 2: Semi-Implicit Euler

**File:** `src/mpe/integrators/semi_implicit_euler.py`

**Update Equations:**

$$
\begin{aligned}
v_{n+1} &= v_n + \Delta t \cdot a_n \\
x_{n+1} &= x_n + \Delta t \cdot v_{n+1} \quad \text{(uses new velocity)}
\end{aligned}
$$

**Key Difference:** Position update uses **updated velocity**, not old velocity.

**Properties:**

| Property | Value | Implication |
|----------|-------|-------------|
| **Order** | 1st order | Same local error as Explicit Euler |
| **Symplectic** | âœ… Yes | Preserves modified Hamiltonian |
| **Time-Reversible** | âŒ No | Not symmetric |
| **Force Evaluations** | 1 per step | Same cost as Explicit Euler |

**Stability:** Stable for oscillators. Energy oscillates but doesn't grow.

---

### Implementation 3: Velocity Verlet

**File:** `src/mpe/integrators/verlet.py`

**Update Equations:**

$$
\begin{aligned}
x_{n+1} &= x_n + v_n \Delta t + \frac{1}{2}a_n (\Delta t)^2 \\
v_{n+1} &= v_n + \frac{1}{2}(a_n + a_{n+1}) \Delta t
\end{aligned}
$$

**Implementation:**

```python
def step(self, state, force_model, mass, t, dt):
    # Acceleration at current state
    F = force_model.compute(state, t)
    a = F / mass
    
    # Update position
    new_x = state.x + state.v * dt + 0.5 * a * dt * dt
    
    # Acceleration at new position
    new_state_intermediate = State1D(new_x, state.v)
    F_new = force_model.compute(new_state_intermediate, t + dt)
    a_new = F_new / mass
    
    # Update velocity using average acceleration
    new_v = state.v + 0.5 * (a + a_new) * dt
    
    return State1D(new_x, new_v)
```

**Properties:**

| Property | Value | Implication |
|----------|-------|-------------|
| **Order** | 2nd order | Local error $O(\Delta t^2)$ |
| **Symplectic** | âœ… Yes | Preserves phase space structure |
| **Time-Reversible** | âœ… Yes | Symmetric update scheme |
| **Force Evaluations** | 2 per step | 2Ã— cost of Euler methods |

**This is the gold standard for molecular dynamics and orbital mechanics.**

---

### Implementation 4: Runge-Kutta 4 (RK4)

**File:** `src/mpe/integrators/rk4.py`

**Update Equations:**

$$
\begin{aligned}
k_1 &= f(t_n, y_n) \\
k_2 &= f(t_n + \frac{\Delta t}{2}, y_n + \frac{\Delta t}{2}k_1) \\
k_3 &= f(t_n + \frac{\Delta t}{2}, y_n + \frac{\Delta t}{2}k_2) \\
k_4 &= f(t_n + \Delta t, y_n + \Delta t k_3) \\
y_{n+1} &= y_n + \frac{\Delta t}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{aligned}
$$

**Properties:**

| Property | Value | Implication |
|----------|-------|-------------|
| **Order** | 4th order | Local error $O(\Delta t^4)$ |
| **Symplectic** | âŒ No | Does not preserve Hamiltonian structure |
| **Time-Reversible** | âŒ No | Not symmetric |
| **Force Evaluations** | 4 per step | 4Ã— cost of basic methods |

**Limitation:** Despite high local accuracy, systematic drift accumulates over long horizons in conservative systems.

---

## Module 4: Simulator â€” Orchestration Layer

**File:** `src/mpe/core/simulator.py`

### Purpose
Orchestrate integration loop and manage simulation execution.

### Implementation

```python
class Simulator:
    def __init__(self, integrator, force_model, mass):
        self.integrator = integrator
        self.force_model = force_model
        self.mass = mass
    
    def simulate(self, initial_state, dt, steps):
        # Preallocate arrays
        states = np.zeros((steps + 1, 2))
        times = np.zeros(steps + 1)
        
        # Initialize
        state = initial_state
        states[0] = [state.x, state.v]
        times[0] = 0.0
        
        # Integration loop
        for i in range(steps):
            state = self.integrator.step(
                state, self.force_model, self.mass, times[i], dt
            )
            states[i + 1] = [state.x, state.v]
            times[i + 1] = times[i] + dt
        
        return times, states[:, 0], states[:, 1]
```

### Responsibilities

âœ… Loop management â€” Execute integration for specified number of steps  
âœ… State propagation â€” Pass state through integrator  
âœ… Time tracking â€” Advance time by $\Delta t$ each step  
âœ… History recording â€” Store trajectory in preallocated arrays  

### What It Does NOT Do

âŒ Compute forces (delegated to `ForceModel`)  
âŒ Perform integration (delegated to `Integrator`)  
âŒ Analyze results (delegated to `analysis` module)  

**Single Responsibility Principle enforced.**

---

## Module 5: TimeKeeper â€” Temporal State Management

**File:** `src/mpe/core/timekeeper.py`

### Purpose
Centralized time management to avoid floating-point accumulation errors.

### Implementation

```python
class TimeKeeper:
    def __init__(self, dt: float):
        self.dt = dt
        self.current_time = 0.0
    
    def step(self):
        self.current_time += self.dt
    
    def reset(self):
        self.current_time = 0.0
```

### Design Rationale

| Design Choice | Problem Solved |
|--------------|----------------|
| **Explicit time tracking** | Avoids implicit `t = i * dt` pattern |
| **Centralized management** | Single source of truth for current time |
| **Floating-point safety** | Prevents cumulative rounding errors from `t = i * dt` |
| **Extensibility** | Facilitates future adaptive timestepping support |

---

## Module 6: Analysis Modules

### 6.1 Energy Module â€” Energy Conservation Tracking

**File:** `src/mpe/analysis/energy.py`

**Core Functions:**

```python
def oscillator_energy(x, v, m, k):
    """Compute total mechanical energy."""
    kinetic = 0.5 * m * v**2
    potential = 0.5 * k * x**2
    return kinetic + potential

def energy_drift(energy):
    """Compute energy drift relative to initial value."""
    return energy - energy[0]

def relative_energy_drift(energy):
    """Compute relative energy drift as percentage."""
    return (energy - energy[0]) / energy[0]
```

**Purpose:** For Hamiltonian systems, energy should be conserved. Drift indicates integrator failure to preserve structure.

**Usage:** Primary diagnostic for long-term stability assessment.

---

### 6.2 Error Module â€” Analytical Comparison

**File:** `src/mpe/analysis/error.py`

**Core Functions:**

```python
def analytic_solution(t_array, A, omega, phi=0):
    """Exact solution for harmonic oscillator."""
    return A * np.cos(omega * t_array + phi)

def absolute_error(x_numeric, x_analytic):
    """Pointwise absolute error."""
    return np.abs(x_numeric - x_analytic)

def l2_error(x_numeric, x_analytic):
    """L2 norm of error over trajectory."""
    return np.sqrt(np.mean((x_numeric - x_analytic)**2))

def max_error(x_numeric, x_analytic):
    """Maximum absolute error."""
    return np.max(np.abs(x_numeric - x_analytic))
```

**Purpose:** Quantify numerical solution deviation from exact analytical solution.

**Metrics:**
- L2 error: Global error metric over entire trajectory
- Max error: Worst-case deviation  
- Absolute error: Pointwise deviation array

---

### 6.3 Stability Module â€” Stability Detection

**File:** `src/mpe/analysis/stability.py`

**Core Function:**

```python
def is_unstable(positions, velocities, mass, k,
                amp_threshold=100, energy_threshold=0.1):
    """
    Determine if simulation is unstable based on multiple criteria.
    
    Criteria:
    1. No NaN or Inf values
    2. Amplitude remains bounded
    3. Energy drift < 10% (most stringent)
    
    Returns:
        bool: True if unstable, False if stable
    """
    # Check for NaN/Inf
    if np.any(np.isnan(positions)) or np.any(np.isinf(positions)):
        return True
    if np.any(np.isnan(velocities)) or np.any(np.isinf(velocities)):
        return True
    
    # Check amplitude explosion
    if np.max(np.abs(positions)) > amp_threshold:
        return True
    
    # Check energy drift (most important)
    energy = oscillator_energy(positions, velocities, mass, k)
    relative_drift = np.abs(energy - energy[0]) / energy[0]
    
    if np.max(relative_drift) > energy_threshold:
        return True
    
    return False
```

**Stability Criteria (all must pass):**

| Criterion | Threshold | Purpose |
|-----------|-----------|---------|
| **No NaN/Inf** | Any occurrence fails | Detect catastrophic numerical failure |
| **Bounded amplitude** | $\|x\| < 100$ for $\|x_0\| \approx 1$ | Detect explosion to infinity |
| **Energy drift** | $\|\Delta E\|/E_0 < 10\%$ | Detect structural preservation failure (most stringent) |

**Why 10% Energy Drift Threshold?**

- Stricter than explosion detection
- Reveals structural failures even when system doesn't blow up  
- Scientifically realistic (most physics applications require < 5% conservation)  
- Successfully differentiates symplectic (pass) from non-symplectic (fail) integrators

---

**Maximum Stable Timestep Detection:**

```python
def find_max_stable_dt(simulator_factory, integrator, force_model,
                       mass, k, initial_state, dt_values, steps=50000):
    """
    Binary search for maximum stable timestep.
    
    Returns:
        (max_stable_dt, stability_results_dict)
    """
    max_stable_dt = None
    stability_results = {}
    
    # Test in increasing order, stop at first failure
    for dt in dt_values:
        sim = simulator_factory(integrator, force_model, mass)
        t, x, v = sim.simulate(initial_state, dt, steps)
        
        unstable = is_unstable(x, v, mass, k)
        stability_results[dt] = not unstable
        
        if unstable:
            break  # Found stability boundary
        else:
            max_stable_dt = dt
    
    return max_stable_dt, stability_results
```

**Strategy:** Test timesteps in increasing order; stop at first failure. This yields $\Delta t_{\text{max}}$ efficiently.

---

<a name="phase2"></a>
# ğŸ”¬ PHASE 2: NUMERICAL INTEGRATOR ANALYSIS

## 2.1 Research Methodology & Experimental Design

### Primary Research Questions

Phase 2 investigates five fundamental questions about numerical integrator behavior:

| Question | Focus Area | Measurable Outcome |
|----------|-----------|-------------------|
| **Q1: Energy Conservation** | Which integrators preserve Hamiltonian $H = \text{const}$? | Energy drift $\Delta E(t)/E(0)$ over extended time |
| **Q2: Stability Boundaries** | What is maximum stable timestep $\Delta t_{\text{max}}$? | Largest $\Delta t$ satisfying 10% drift criterion |
| **Q3: Computational Cost** | How do wall-clock times compare? | Nanoseconds per integration step |
| **Q4: Effective Throughput** | What is simulated time rate under constraints? | Simulated-seconds per real-second |
| **Q5: Order vs. Structure** | Does high order guarantee long-term reliability? | RK4 (4th order) vs Verlet (2nd order) comparison |

### Experimental Hypothesis

**Null Hypothesis (Hâ‚€):** All integrators with equal or higher formal order of accuracy will exhibit comparable long-term stability and throughput performance.

**Alternative Hypothesis (Hâ‚):** Symplectic structure preservation is a more reliable predictor of long-term stability than local truncation error order for Hamiltonian systems.

**Experimental Approach:** Rigorous empirical measurement under controlled conditions. Theoretical analysis provides bounds but cannot predict accumulated drift over $10^4$ steps.

---

## 2.2 Stability Criterion Development

### Evolution of Stability Metrics

The definition of "stability" critically determines experimental conclusions. This project employed iterative refinement:

#### Version 1.0: Amplitude-Based Criterion (Initial, Inadequate)

```python
Unstable if:
  - np.any(np.isnan(positions))
  - np.any(np.isinf(positions))
  - np.max(np.abs(positions)) > threshold
```

**Detection:** Only catastrophic failure (explosion to infinity or NaN).

**Problem:** Many integrators fail **structurally** without amplitude explosion. Under this metric, RK4 appeared "stable" with $\Delta t_{\text{max}} \approx 0.5$, masking systematic energy drift.

---

#### Version 2.0: Energy-Drift-Based Criterion (Refined, Adopted)

```python
Unstable if:
  - NaN or Inf present (catastrophic failure)
  - Amplitude explosion (secondary check)
  - max|E(t) - E(0)|/E(0) > 0.1 (energy drift > 10%)
```

**Theoretical Foundation:** For Hamiltonian systems, exact flow preserves total energy:

$$
\frac{dH}{dt} = 0 \quad \Rightarrow \quad H(t) = H(0) \quad \forall t
$$

Any violation $|H(t) - H(0)| > \epsilon$ indicates the numerical integrator is **not evolving on the correct manifold**, even if trajectories remain bounded.

**10% Threshold Justification:**

| Consideration | Justification |
|---------------|---------------|
| **Stricter than explosion** | Catches drift before catastrophic failure |
| **Scientifically realistic** | Most physics applications require < 5% energy conservation |
| **Discriminative** | Successfully differentiates symplectic (pass) vs non-symplectic (fail) |
| **Domain-standard** | Aligns with MD simulation practices (GROMACS, LAMMPS) |

**Impact:** Under refined criterion, RK4 **fails** due to monotonic energy drift despite high local accuracy. This represents true integrator behavior.

---

### Metric Validation

The energy-drift criterion aligns with established practice in:

- **Molecular dynamics** â€” GROMACS, LAMMPS energy monitoring  
- **Orbital mechanics** â€” NASA trajectory integration standards  
- **Climate modeling** â€” Long-term energy balance requirements  

**Validation Result:** Criterion successfully exposes structural failures invisible to amplitude-only metrics.

---

## 2.3 Experimental Configuration

### Test System Parameters

All experiments used identical physical configuration:

```python
# Physical parameters
m = 1.0              # mass [kg]
k = 10.0             # spring constant [N/m]
omega = sqrt(k/m)    # = 3.162 rad/s (natural frequency)
T_period = 2Ï€/omega  # = 1.987 s (oscillation period)

# Initial conditions
x0 = 1.0             # initial displacement [m]
v0 = 0.0             # initial velocity [m/s] (released from rest)
E0 = 0.5 * k * x0^2  # = 5.0 J (initial energy, all potential)

# Timestep sweep parameters
dt_min = 0.0005      # minimum tested timestep [s]
dt_max = 1.0         # maximum tested timestep [s]
n_samples = 800      # number of timesteps tested
dt_values = np.linspace(dt_min, dt_max, n_samples)

# Simulation duration per test
steps_per_test = 10000  # integration steps
# Note: Actual simulated time varies with dt
#   Large dt (0.1 s):   T_sim = 10,000 Ã— 0.1 = 1,000 s â‰ˆ 503 periods
#   Small dt (0.001 s): T_sim = 10,000 Ã— 0.001 = 10 s â‰ˆ 5 periods
```

### Simulated Time Horizons

The fixed-step approach results in variable simulated time:

| Timestep $\Delta t$ | Total Simulated Time | Number of Oscillations |
|--------------------|---------------------|----------------------|
| 0.001 s | 10 s | ~5 periods |
| 0.01 s | 100 s | ~50 periods |
| 0.1 s | 1,000 s | ~503 periods |
| 0.5 s | 5,000 s | ~2,517 periods |

**Design rationale:** Captures both short-term accuracy (small $\Delta t$, high resolution) and long-term stability (large $\Delta t$, many periods).

---

### Statistical Considerations

| Aspect | Approach | Justification |
|--------|----------|---------------|
| **Monte Carlo Averaging** | Not required | Deterministic system; single trajectory representative |
| **Numerical Precision** | float64 throughout | Isolates integrator error from roundoff |
| **Warm-up Period** | 100 iterations before timing | Excludes cold-start artifacts (bytecode compilation, cache) |
| **Timing Iterations** | 10,000 per benchmark | Amortizes timer overhead; provides statistical significance |
| **Timer Resolution** | Nanosecond (`time.perf_counter_ns()`) | Sufficient for sub-microsecond integration steps |

---

## 2.4 Integrator Comparison Matrix

### Theoretical Properties

| Integrator | Order | Symplectic | Time-Reversible | Force Evals/Step | Expected Stability |
|------------|-------|------------|-----------------|------------------|-------------------|
| **Explicit Euler** | 1st | âŒ | âŒ | 1 | Poor (unstable for oscillators) |
| **Semi-Implicit Euler** | 1st | âœ… | âŒ | 1 | Moderate (bounded energy) |
| **Velocity Verlet** | 2nd | âœ… | âœ… | 2 | Excellent (symplectic + reversible) |
| **RK4** | 4th | âŒ | âŒ | 4 | Short-term only (systematic drift) |

**Key Insight:** Symplectic structure preservation predicts long-term stability better than truncation error order for conservative systems.

---

<a name="experiments"></a>
# ğŸ§ª EXPERIMENTAL METHODOLOGY

## Stability Table Experiment

**File:** `src/experiments/stability_table.py`

### Purpose
Generate comprehensive performance and stability comparison table for all integrators.

### Metrics Measured

#### Metric 1: Maximum Stable Timestep ($\Delta t_{\text{max}}$)

**Definition:** Largest timestep satisfying stability criteria over 10,000 steps.

**Measurement:**

```python
def find_max_stable_dt(integrator, force, mass, k, initial_state, dt_values):
    for dt in dt_values:  # Test in increasing order
        sim = Simulator(integrator, force, mass)
        t, x, v = sim.simulate(initial_state, dt, steps=10000)
        
        if is_unstable(x, v, mass, k, energy_threshold=0.1):
            return previous_dt  # First failure â†’ return previous
        
        previous_dt = dt
    
    return dt_values[-1]  # All passed â†’ return maximum
```

**Significance:** Larger $\Delta t_{\text{max}}$ â†’ fewer steps required â†’ faster simulation.

---

#### Metric 2: Nanoseconds per Step (ns/step)

**Definition:** Wall-clock time per integration step.

**Measurement Methodology:**

```python
def measure_step_performance(integrator, force, mass, state, dt,
                              warmup=100, iterations=10000):
    """
    High-precision timing with warm-up period.
    """
    # Warm-up (bytecode compilation, cache)
    for _ in range(warmup):
        state = integrator.step(state, force, mass, 0.0, dt)
    
    # Timed measurement
    start = time.perf_counter_ns()
    for _ in range(iterations):
        state = integrator.step(state, force, mass, 0.0, dt)
    end = time.perf_counter_ns()
    
    return (end - start) / iterations  # ns per step
```

**Why warm-up?**
- Python bytecode compilation  
- CPU cache warming  
- Branch predictor training  

**Why 10,000 iterations?**
- Amortizes timing overhead  
- Provides statistical significance  
- Reduces measurement noise

---

#### Metric 3: FLOPs (Floating-Point Operations per Step)

**Estimation Methodology:** Manual operation counting in each integrator.

**Explicit Euler:**

```python
F = -k * x           # 1 multiply
a = F / m            # 1 divide
new_x = x + dt * v   # 1 multiply, 1 add
new_v = v + dt * a   # 1 multiply, 1 add
# Total: ~6 FLOPs
```

**Velocity Verlet:**

```python
# First force evaluation
F = -k * x           # 2 ops
a = F / m
# Position update
new_x = x + v*dt + 0.5*a*dtÂ²  # 5 ops (mult, mult, mult, add, add)
# Second force evaluation
F_new = -k * new_x   # 2 ops
a_new = F_new / m
# Velocity update
new_v = v + 0.5*(a+a_new)*dt  # 4 ops (add, mult, mult, add)
# Total: ~13 FLOPs
```

**RK4:**

Four intermediate force evaluations + weighted averaging â‰ˆ **38 FLOPs**.

**Rationale:** Hardware-level FLOP counting requires profiler tools. Manual estimation provides order-of-magnitude understanding and algorithmic complexity comparison.

---

#### Metric 4: Simulated Time per Real Second

**Definition:** How many simulated seconds advance per real-world second under stability constraints?

**Formula:**

$$
\text{Sim-time/sec} = \frac{\Delta t_{\text{max stable}}}{t_{\text{step}}} = \frac{\Delta t_{\text{max}} \times 10^9}{\text{ns/step}}
$$

**Example Calculation (Verlet):**
- $\Delta t_{\text{max}} = 0.256$ s  
- ns/step = 1258  
- Sim-time/sec = $(0.256 \times 10^9) / 1258 = 203,173$ sim-s/real-s

**Interpretation:** Verlet simulates **203,000 seconds per real second** when operating at maximum stable timestep.

**Significance:** This is the **true performance metric** â€” it accounts for both computational cost AND stability constraints.

---

## Experiment Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Initialize Integrators & Force Models  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. For Each Integrator:                    â”‚
â”‚     - Find max stable dt                    â”‚
â”‚     - Measure ns/step at that dt            â”‚
â”‚     - Count FLOPs                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Calculate Derived Metrics:              â”‚
â”‚     - Simulated-time/real-second            â”‚
â”‚     - Relative speedups                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Generate Formatted Table                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<a name="results"></a>
# ğŸ“Š RESULTS & PERFORMANCE ANALYSIS

## Comprehensive Stability & Performance Table

### Phase 2 Final Results

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              NUMERICAL INTEGRATOR STABILITY & PERFORMANCE ANALYSIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Integrator          Max Stable dt    ns/step    FLOPs   Sim-time/sec  
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Euler                    0.000500      602.80        6         829.46
SemiImplicit             0.045534      649.24        6      70,133.99
Verlet                   0.255691    1,258.49       13     203,173.24
RK4                           NaN    3,417.92       38           0.00
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Metric Definitions:
  â€¢ Max Stable dt: Largest timestep maintaining E_drift < 10% over 10,000 steps
  â€¢ ns/step: Wall-clock nanoseconds per integration step
  â€¢ FLOPs: Floating-point operations per step (estimated)
  â€¢ Sim-time/sec: Simulated seconds advanced per real-world second
                  (accounts for stability constraints)

System Parameters:
  â€¢ Test system: 1D harmonic oscillator (m=1.0, k=10.0, Ï‰=3.162 rad/s)
  â€¢ Initial conditions: xâ‚€=1.0, vâ‚€=0.0, Eâ‚€=5.0 J
  â€¢ Stability criterion: |Î”E|/Eâ‚€ < 0.10 (10% energy drift threshold)
  â€¢ Integration steps: 10,000 per test
  â€¢ Timestep range tested: [0.0005, 1.0] seconds (800 values)
```

---

## Analysis by Integrator

### Integrator 1: Explicit Euler â€” âŒ UNSUITABLE

**Quantitative Results:**

| Metric | Value | Interpretation |
|--------|-------|----------------|
| Max stable $\Delta t$ | 0.0005 s | Extremely restrictive; 512Ã— smaller than Verlet |
| ns/step | 603 | Fastest per-step execution |
| Sim-time/sec | 829 | **Worst throughput despite fastest steps** |

**Observed Behavior:**
- Energy grows exponentially with time  
- Even tiny $\Delta t = 0.0005$ fails 10% drift criterion over 10,000 steps  
- Amplitude diverges for $\Delta t > 0.001$  

**Theoretical Explanation:**

Update matrix for harmonic oscillator:

$$
\begin{bmatrix} x_{n+1} \\ v_{n+1} \end{bmatrix} = \begin{bmatrix} 1 & \Delta t \\ -\omega^2 \Delta t & 1 \end{bmatrix} \begin{bmatrix} x_n \\ v_n \end{bmatrix}
$$

Eigenvalue magnitude:

$$
|\lambda| = \sqrt{1 + (\omega \Delta t)^2} > 1 \quad \forall \Delta t > 0
$$

**Amplification factor per step** â†’ exponential growth over many iterations.

**Phase Space Behavior:** Trajectory spirals outward, not forming closed curves.

**Verdict:** Fundamentally unsuitable for oscillatory dynamics. Use only for:
- Very short simulations
- Heavily damped systems  
- Non-oscillatory dynamics

---

### Integrator 2: Semi-Implicit Euler â€” âœ… USABLE

**Quantitative Results:**

| Metric | Value | Comparison to Explicit Euler |
|--------|-------|------------------------------|
| Max stable $\Delta t$ | 0.045 s | **91Ã— larger** than Explicit Euler |
| ns/step | 649 | 8% slower per-step |
| Sim-time/sec | 70,134 | **85Ã— faster throughput** |

**Observed Behavior:**
- Energy oscillates around initial value  
- No monotonic drift  
- Qualitatively correct dynamics preserved  

**Theoretical Explanation:**

Symplectic integrators preserve a **modified Hamiltonian** $\tilde{H}$:

$$
\tilde{H}(x, v) = H(x, v) + O(\Delta t^2)
$$

where $\tilde{H}$ is conserved exactly by the numerical scheme. This implies:

$$
|\tilde{H}(t) - \tilde{H}(0)| = 0 \quad \Rightarrow \quad \text{bounded motion}
$$

**Phase Space Behavior:** Trajectories form closed curves (not spirals), preserving area.

**Verdict:** Reliable choice for:
- Moderate-accuracy simulations  
- Real-time applications needing minimal cost  
- Educational demonstrations of symplectic methods  

**Trade-off:** First-order accuracy limits precision; use Verlet when higher accuracy needed.

---

### Integrator 3: Velocity Verlet â€” âœ… GOLD STANDARD

**Quantitative Results:**

| Metric | Value | Comparison to Explicit Euler |
|--------|-------|------------------------------|
| Max stable $\Delta t$ | 0.256 s | **512Ã— larger** |
| ns/step | 1,258 | 2.1Ã— slower per-step |
| Sim-time/sec | **203,173** | **245Ã— faster throughput** |

This is the **highest effective throughput** of all tested integrators.

**Observed Behavior:**
- Minimal energy drift (< 0.1% over 10,000 steps)  
- Long-term stability maintained  
- Second-order local accuracy  

**Why Verlet Dominates:**

| Property | Benefit |
|----------|---------|
| **Symplectic** | Preserves phase space volume; energy bounded |
| **Time-reversible** | $x(t) \to x(t+\Delta t) \to x(t)$ exact; eliminates systematic bias |
| **Second-order** | Local error $O(\Delta t^2)$ vs $O(\Delta t)$ for Semi-Implicit |

**Despite 2.1Ã— higher cost per step:**
- Allows **5.6Ã— larger timestep** than Semi-Implicit Euler  
- Net result: **2.9Ã— faster throughput** than Semi-Implicit  

**Phase Space Behavior:** Near-perfect closed curves with minimal drift over hundreds of periods.

**Industrial Adoption:**

| Domain | Software | Usage |
|--------|----------|-------|
| Molecular Dynamics | LAMMPS, GROMACS, NAMD | Default integrator |
| Orbital Mechanics | N-body simulators, JPL ephemeris | Long-term trajectory propagation |
| Game Physics | Unity, Unreal Engine | Stable particle systems |

**Verdict:** **Industry standard for conservative dynamics.** Use whenever:
- Energy conservation required  
- Long simulation horizons  
- Hamiltonian structure present  

---

### Integrator 4: RK4 â€” âŒ FAILED (Long-Term Conservative Systems)

**Quantitative Results:**

| Metric | Value | Interpretation |
|--------|-------|----------------|
| Max stable $\Delta t$ | **NaN** | Fails 10% energy drift criterion at all tested timesteps |
| ns/step | 3,418 | 5.7Ã— slower than Explicit Euler |
| Sim-time/sec | **0** | Unusable for long-term Hamiltonian simulation |

**Observed Behavior:**
- Extremely accurate **short-term** (first ~10 periods)  
- Systematic energy drift over long horizons (10,000 steps)  
- Not explosion â€” gradual monotonic drift  

**Theoretical Explanation:**

RK4 is **not symplectic**. It preserves local truncation error but not geometric structure.

Energy error accumulation over $N$ steps:

$$
E(t_N) = E(0) + N \times \epsilon_{\text{local}}
$$

where $\epsilon_{\text{local}} = O(\Delta t^4)$.

Even though $O(\Delta t^4)$ is tiny per step, over $N = 10,000$ steps:

$$
\Delta E_{\text{cumulative}} = 10,000 \times O(\Delta t^4)
$$

For $\Delta t = 0.1$, this accumulates to several percent drift even with 4th-order local accuracy.

**Key Lesson:**

$$
\boxed{\text{Local accuracy} \neq \text{Global reliability}}
$$

High-order non-symplectic methods are inappropriate for long-horizon conservative systems.

---

**When to Use RK4:**

| Scenario | Reason |
|----------|--------|
| **Short simulations** | Drift doesn't accumulate over few steps |
| **Non-conservative systems** | Energy not required to be conserved |
| **Smooth, non-oscillatory dynamics** | Damped systems, control problems |
| **Accuracy over stability** | When precise trajectory matters more than long-term energy |

**When NOT to Use RK4:**

| Scenario | Reason |
|----------|--------|
| **Long-horizon Hamiltonian systems** | Systematic drift violates energy conservation |
| **Oscillatory dynamics** | Non-symplectic structure causes phase error accumulation |
| **Orbital mechanics** | Artificial orbital decay from energy drift |
| **Molecular dynamics** | Temperature drift from energy non-conservation |

**Verdict:** Wrong tool for this problem. Use symplectic methods (Verlet) for conservative systems.

---

## Performance Comparison Visualization

### Effective Throughput (Log Scale)

```
Simulated-Seconds per Real-Second (logâ‚â‚€ scale):

Euler        â– 829
             â”‚
SemiImplicit â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 70,134
             â”‚                   (85Ã— faster than Euler)
Verlet       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 203,173
             â”‚                             (245Ã— faster than Euler)
RK4          (failed â€” unusable for long-term conservative dynamics)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Interpretation:
  â€¢ Verlet achieves 245Ã— higher throughput than Euler under stability constraints
  â€¢ Symplectic structure (SemiImplicit, Verlet) essential for bounded energy
  â€¢ High order (RK4) does not guarantee long-term stability
```

---

### Stability Boundary Comparison

```
Maximum Stable Timestep (logâ‚â‚€ scale):

Euler        â– dt_max = 0.0005 s
             â”‚
SemiImplicit â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.045 s  (91Ã— larger than Euler)
             â”‚
Verlet       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.256 s  (512Ã— larger than Euler)
             â”‚
RK4          (fails energy conservation criterion at all tested timesteps)
```

**Observation:** Symplectic integrators permit orders-of-magnitude larger timesteps while maintaining energy conservation.

---

<a name="phase3"></a>
# âš¡ PHASE 3: BATCH SIMULATION & THROUGHPUT ENGINEERING

## 3.1 Phase Objectives

After establishing numerical stability principles in Phase 2, Phase 3 shifts focus to **raw simulation throughput** and hardware utilization:

### Primary Goals

| Goal | Objective | Success Metric |
|------|-----------|----------------|
| **Batch Simulation** | Implement vectorized simulation for $N$ particles | Support N âˆˆ {1, 1000, 100,000} |
| **Backend Comparison** | Evaluate multiple optimization levels | Python loop, NumPy, PyTorch |
| **Throughput Measurement** | Characterize performance across scales | Particle-steps/sec, memory bandwidth |
| **Bottleneck Identification** | Determine limiting factor at each scale | Overhead, interpreter, memory bandwidth |
| **Memory Optimization** | Optimize access patterns | Target: > 1B particle-steps/sec |

### Research Questions

1. How does performance scale from single particle to 100,000 particles?
2. What are the distinct performance regimes?  
3. When does the system transition from compute-bound to memory-bound?  
4. How much performance gain from memory access optimization?  
5. What is sustained memory bandwidth for each backend?

---

## 3.2 Backend Implementations

Three backends representing different optimization philosophies:

### Backend 1: PythonLoop â€” Baseline

**Implementation:**

```python
for i in range(N):
    v[i] += dt * a[i]
    x[i] += dt * v[i]
```

**Characteristics:**

| Property | Description |
|----------|-------------|
| **Iteration** | Scalar, per-particle Python loop |
| **Vectorization** | None â€” interpreted element-wise |
| **Overhead** | Interpreter overhead per particle |
| **Use Case** | Baseline for measuring vectorization benefit |

**Expected Performance:** Interpreter-bound; saturates at fixed particle-updates/sec regardless of $N$.

---

### Backend 2: NumPy Vectorized â€” Optimized

**Implementation:**

```python
v += dt * a  # Vectorized update
x += dt * v  # Vectorized update
```

**Characteristics:**

| Property | Description |
|----------|-------------|
| **Iteration** | Implicit â€” NumPy handles loop |
| **Vectorization** | Full SIMD exploitation |
| **Overhead** | Fixed per-operation; amortizes at scale |
| **Use Case** | High-performance numerical computing |

**Expected Performance:** Memory-bandwidth-bound at large $N$; scales linearly with particle count.

---

### Backend 3: PyTorch CPU â€” Tensor Framework

**Implementation:**

```python
v = v + dt * a  # Tensor operation
x = x + dt * v  # Tensor operation
```

**Characteristics:**

| Property | Description |
|----------|-------------|
| **Iteration** | Tensor framework abstraction |
| **Vectorization** | SIMD + potential kernel fusion |
| **Overhead** | Framework overhead + autograd machinery (even if unused) |
| **Use Case** | GPU-ready code; future acceleration |

**Expected Performance:** Similar to NumPy but with additional framework overhead.

---

## 3.3 Initial Throughput Results (Before Optimization)

### Comprehensive Benchmarking

| Particles | Backend | Steps/sec | Particle-Steps/sec | Est. BW (GB/s) | Regime |
|-----------|---------|-----------|-------------------:|---------------:|--------|
| **1** | PythonLoop | 1.35M | 1.35M | 0.043 | Overhead-bound |
| | NumPy | 176k | 176k | 0.0056 | Overhead-bound |
| | TorchCPU | 18k | 18k | 0.0006 | Overhead-bound |
| **1,000** | PythonLoop | 1.8k | 1.8M | 0.058 | Interpreter-bound |
| | NumPy | 250k | 250M | 8.0 | Memory-bound (transition) |
| | TorchCPU | 64k | 64M | 2.07 | Memory-bound (transition) |
| **100,000** | PythonLoop | 19 | 1.9M | 0.060 | Interpreter-saturated |
| | NumPy | 8.4k | 842M | 26.9 | Memory-bandwidth-bound |
| | TorchCPU | 4.7k | 472M | 15.1 | Memory-bandwidth-bound |

**Bandwidth Estimation (Initial):** Assumed 32 bytes/particle/step (float64, 4 memory accesses).

---

## 3.4 Performance Regime Analysis

### Regime 1: N=1 (Micro-Workload, Overhead-Bound)

**Observation:** PythonLoop dominates (1.35M vs 176k NumPy).

**Explanation:**

| Backend | Overhead Source | Impact at N=1 |
|---------|----------------|---------------|
| PythonLoop | Minimal â€” direct loop | Low overhead amortized over single operation |
| NumPy | Array allocation, function call overhead | High fixed cost exceeds compute |
| TorchCPU | Tensor creation, framework overhead | Highest fixed cost |

**Lesson:** Vectorization requires sufficient scale to amortize setup cost. For tiny workloads, simple loops win.

---

### Regime 2: N=1,000 (Mid-Scale, Interpreter-Bound Transition)

**Critical Observations:**

**PythonLoop:**
- Steps/sec: 1.35M â†’ 1.8k (750Ã— decrease)  
- Particle-steps/sec: ~1.8M (constant)  

**Interpretation:** PythonLoop is **interpreter-bound**, not memory-bound.

> **Finding:** Interpreter overhead per particle is fixed. Total throughput cannot exceed ~2M particle-updates/sec regardless of vectorization attempts within Python loop.

**NumPy:**
- Particle-steps/sec: 176k â†’ 250M (1,420Ã— increase)  
- Bandwidth: 8 GB/s (real DRAM traffic)  

**Interpretation:** NumPy transitions from overhead-bound to memory-bound. Vectorization now amortized; reaching hardware.

**TorchCPU:**
- Particle-steps/sec: 18k â†’ 64M (3,555Ã— increase)  
- Bandwidth: 2.07 GB/s  

**Interpretation:** Similar vectorization benefit but framework overhead limits absolute performance.

---

### Regime 3: N=100,000 (Large-Scale, Memory-Bandwidth-Bound)

**PythonLoop:**
- Particle-steps/sec: flat at ~1.9M  
- Confirmed as interpreter-saturated  
- Cannot leverage parallelism or hardware capabilities  

**NumPy:**
- Particle-steps/sec: 842M  
- Bandwidth: ~26.9 GB/s  
- **Approaching equipment DRAM bandwidth limit**  

**TorchCPU:**
- Particle-steps/sec: 472M  
- Bandwidth: ~15.1 GB/s  
- Still fast but below NumPy due to framework overhead  

**Key Finding:**

> At N=100,000, NumPy and TorchCPU are **memory-bandwidth-limited**. Further FLOP reduction won't help; must reduce memory traffic.

---

## 3.5 Optimization 1: In-Place NumPy Updates

### Problem Identified

Original NumPy implementation:

```python
a = -k_over_m * x      # Allocates new array
x = x + dt * v         # Allocates new array
v = v + dt * a         # Allocates new array
```

**Issue:** Every integration step creates temporary arrays:
- Extra memory allocations  
- Unnecessary memory copies  
- Increased garbage collection pressure  
- More DRAM traffic than necessary  

**Theoretical Analysis:**

| Operation | Memory Operations (Before) |
|-----------|---------------------------|
| Compute $a = -kx/m$ | Read $x$, write $a$ |
| Update $x = x + dt \cdot v$ | Read $x$, read $v$, allocate $x_{\text{new}}$, write $x_{\text{new}}$ |
| Update $v = v + dt \cdot a$ | Read $v$, read $a$, allocate $v_{\text{new}}$, write $v_{\text{new}}$ |

**Total:** 6 allocations + 10 memory operations per step.

---

### Solution: In-Place Array Operations

**Optimized Implementation:**

```python
# Compute acceleration (still allocates temporary)
a = -k_over_m * x

# In-place updates (reuse existing buffers)
v += dt * a  # Modifies v in-place
x += dt * v  # Modifies x in-place
```

**Improved Memory Pattern:**

| Operation | Memory Operations (After) |
|-----------|--------------------------|
| Compute $a = -kx/m$ | Read $x$, write $a$ (unavoidable) |
| Update $v$ in-place | Read $v$, read $a$, write $v$ (no allocation) |
| Update $x$ in-place | Read $x$, read $v$, write $x$ (no allocation) |

**Total:** 1 allocation + 8 memory operations per step.

**Reduction:** 83% fewer allocations; 20% fewer memory operations.

---

### Results After Optimization 1

| Particles | Backend | Particle-Steps/sec<br>(Before) | Particle-Steps/sec<br>(After) | Improvement |
|-----------|---------|-------------------------------:|------------------------------:|------------:|
| 100,000 | NumPy | 842M | **1.456B** | **+73%** |
| 100,000 | TorchCPU | 472M | ~941M | +99% |

**At N=100,000:**
- NumPy throughput: **842M â†’ 1,456M particle-steps/sec**  
- Estimated bandwidth: 26.9 GB/s â†’ 46.6 GB/s  
- Pure memory traffic reduction effect  

---

### Engineering Insights

**Insight 1: Allocation Elimination**

Reusing buffers instead of malloc/free eliminates allocator overhead and fragmentation.

**Insight 2: Reduced Memory Writes**

Fewer array creations â†’ fewer passes through DRAM â†’ higher effective bandwidth utilization.

**Insight 3: Cache Friendliness**

Arrays stay in L3 cache longer during in-place updates vs allocation-heavy approach.

**Insight 4: GC Pressure Reduction**

Fewer temporary objects â†’ less garbage collection overhead â†’ more consistent performance.

---

**Key Lesson:**

> **Even mathematically trivial code can become allocation-bound at scale.**  
> Memory management is as critical as algorithm design.

This 73% improvement required **zero algorithmic changes** â€” purely memory access pattern optimization.

---

## 3.6 Optimization 2: Precision-Aware Bandwidth Accounting

### Problem Identified

Initial bandwidth estimate assumed:

```python
bytes_per_particle_per_step = 32  # Incorrect assumption
```

This assumed float64 (8 bytes) Ã— 4 memory accesses = 32 bytes/particle.

**Reality Check:** Arrays stored in float32:

```python
x = np.array(..., dtype=np.float32)  # 4 bytes per element
v = np.array(..., dtype=np.float32)  # 4 bytes per element
```

**Actual Memory Operations per Particle per Step:**

| Operation | Memory Access | Bytes (float32) |
|-----------|---------------|-----------------|
| Read $x$ | Load | 4 |
| Read $v$ | Load | 4 |
| Write $x$ | Store | 4 |
| Write $v$ | Store | 4 |
| **Total** | | **16** |

**Correction Required:** 16 bytes/particle, not 32.

---

### Solution: Corrected Bandwidth Calculation

**Updated Formula:**

```python
bytes_per_particle = 16  # float32: 4 accesses Ã— 4 bytes
estimated_bandwidth_GB_per_s = (particle_steps_per_sec Ã— 16) / 1e9
```

---

### Results After Correction

| Particles | Backend | Particle-Steps/sec | Estimated BW<br>(Corrected, GB/s) | System State |
|-----------|---------|-------------------:|----------------------------------:|--------------|
| 100,000 | NumPy | 1.38B | **22.1** | Memory-bandwidth-limited |
| 100,000 | TorchCPU | 941M | **15.1** | Memory-bandwidth-limited |
| 100,000 | PythonLoop | 1.98M | **0.032** | Interpreter-limited |

**NumPy Corrected Bandwidth:** ~22.1 GB/s

**Interpretation:**
- Below theoretical peak DRAM bandwidth (~40-60 GB/s for DDR4)  
- Realistic sustained bandwidth accounting for:
  - Cache effects  
  - CPU memory controller overhead  
  - Non-perfect memory access patterns  

---

### Why This Matters

**Accurate Measurement is Prerequisite for Optimization:**

| Benefit | Explanation |
|---------|-------------|
| **Bottleneck Identification** | Confirms memory-bandwidth limitation |
| **Optimization Roadmap** | Further FLOP reduction yields little; must reduce memory traffic |
| **Precision Tradeoffs** | Given bandwidth limit, float32 vs float64 becomes strategic |
| **Hardware Utilization** | 22 GB/s represents good sustained utilization of available DRAM bandwidth |

**Strategic Implication:**

> Bandwidth-bound workloads benefit from precision reduction (float32 vs float64) not just for memory capacity but for **2Ã— memory traffic reduction**.

---

## 3.7 Final Comparative Results

### After Both Optimizations

| Particles | Backend | Steps/sec | Particle-Steps/sec | Bandwidth (GB/s) | Regime |
|-----------|---------|----------:|-------------------:|----------------:|--------|
| **1** | PythonLoop | 955k | 955k | 0.015 | Overhead-bound |
| | NumPy | 104k | 104k | 0.002 | Overhead-bound |
| | TorchCPU | 13k | 13k | 0.0002 | Overhead-bound |
| **1,000** | PythonLoop | 2.0k | 2.0M | 0.032 | Interpreter-bound |
| | NumPy | 299k | 299M | 4.8 | Memory (transition) |
| | TorchCPU | 61k | 61M | 0.98 | Memory (transition) |
| **100,000** | PythonLoop | 19.8 | 1.98M | 0.032 | Interpreter-saturated |
| | NumPy | 13.8k | **1.38B** | **22.1** | Memory-bandwidth-bound |
| | TorchCPU | 9.4k | 941M | **15.1** | Memory-bandwidth-bound |

**Key Achievements:**
- **1.38 billion particle-steps per second** (NumPy, N=100k)  
- **22.1 GB/s sustained memory bandwidth**  
- **73% performance improvement** from in-place optimization  

---

## 3.8 Systems Engineering Insights

### Insight 1: Three Universal Performance Regimes

| Regime | Particle Count | Bottleneck | Dominant Backend | Strategy |
|--------|---------------|------------|------------------|----------|
| **Overhead** | N < 10 | Setup cost | PythonLoop | Minimize abstractions |
| **Interpreter** | 10 < N < 1k | Method calls | PythonLoop (saturates) | Vectorize to escape interpreter |
| **Memory-Bandwidth** | N > 1k | DRAM throughput | NumPy / TorchCPU | Reduce memory traffic |

**Universal Pattern:** This progression appears in all vectorized systems (NumPy, MATLAB, Julia, Fortran arrays).

---

### Insight 2: Local vs Global Optimization

**PythonLoop:**
- Optimized locally (fast per-step interpreter)  
- Fails globally (saturates at ~2M particle-updates/sec)  

**NumPy:**
- Higher per-step overhead  
- Scales linearly to hardware limits  

**Lesson:**

> Global throughput > local optimization.  
> Design for scalability, not micro-optimization.

---

### Insight 3: Memory Pattern Engineering = Algorithm Engineering

**Comparison:**

| Optimization | Type | Performance Gain |
|-------------|------|------------------|
| Select Verlet over Explicit Euler (Phase 2) | Algorithmic | 245Ã— throughput |
| In-place array updates (Phase 3) | Memory pattern | 73% throughput |

**Observation:** Memory pattern optimization delivered gain comparable to algorithmic improvement.

**Conclusion:**

> **Memory access pattern engineering is as important as algorithm selection** for performance-critical applications.

---

### Insight 4: Precision-Aware Hardware Modeling

Correct bandwidth accounting revealed:
- NumPy: ~22 GB/s sustained  
- TorchCPU: ~15 GB/s sustained  
- Both memory-bandwidth-bound  

**Implications for Future Optimization:**
- Reducing FLOPs won't help (memory-bound)  
- Reducing memory traffic will (fewer accesses, blocking, prefetching)  
- Float32 choice strategic (2Ã— bandwidth vs float64)  

---

## 3.9 Relevance to Reinforcement Learning & Batch Simulation

### RL Environment Rollouts

**Performance Formula:**

$$
\text{Throughput} = N_{\text{envs}} \times H_{\text{horizon}} \times N_{\text{particles}} \times \eta_{\text{backend}}
$$

**Optimization Priorities (from Phase 3):**

| Priority | Optimization | Impact on RL |
|----------|-------------|--------------|
| **1. Backend Selection** | NumPy/Torch over loops | 100-1000Ã— speedup at scale |
| **2. Memory Patterns** | In-place updates | 73% faster rollouts |
| **3. Precision Management** | float32 vs float64 | 2Ã— memory bandwidth |
| **4. Batch Size Tuning** | Match hardware regime | Avoid overhead/interpreter-bound regimes |

---

### Batch Simulation Design Principles

**Extracted from Phase 3:**

1. **Choose backend based on workload scale**
   - N < 100: Simple loops acceptable  
   - N > 1000: Vectorization mandatory  

2. **Eliminate allocations in hot loops**
   - In-place updates  
   - Preallocated buffers  

3. **Use precision strategically**
   - Float32 when accuracy permits  
   - 2Ã— bandwidth gain  

4. **Measure bandwidth, not just FLOPs**
   - Memory-bound regimes dominate at scale  
   - Optimize memory traffic, not compute  

5. **Test at realistic batch sizes**
   - Performance characteristics completely different at N=1 vs N=100k  
   - Micro-benchmarks misleading  

---

<a name="lessons"></a>
# ğŸ’¡ ENGINEERING LESSONS LEARNED

## Lesson 1: Stability Definition Determines Experimental Conclusions

### Evolution of Understanding

**Initial Definition (Amplitude-Only):**

```python
Unstable if: np.max(np.abs(positions)) > threshold
```

- **Result:** RK4 appeared "stable" with $\Delta t_{\text{max}} \approx 0.5$  
- **Problem:** Missed systematic energy drift  

**Refined Definition (Energy-Based):**

```python
Unstable if: max|E(t) - E(0)|/E(0) > 0.1
```

- **Result:** RK4 **failed** at all tested timesteps  
- **Conclusion:** True integrator behavior revealed  

### Key Takeaway

> **Measurement methodology critically determines conclusions.**  
> Choose metrics that capture system invariants relevant to application domain.

**Generalization:** In scientific computing, inappropriate metrics lead to incorrect optimization decisions. Validate measurement approach before experimentation.

---

## Lesson 2: Symplectic Structure > Truncation Error Order

### Experimental Evidence

| Method | Order | Symplectic | Energy Drift | Max Stable $\Delta t$ | Verdict |
|--------|-------|------------|--------------|----------------------|---------|
| RK4 | 4th | âŒ | Monotonic growth | NaN (fails) | Unsuitable |
| Verlet | 2nd | âœ… | < 0.1% bounded | 0.256 | Optimal |

**Verlet (2nd order) outperforms RK4 (4th order) for Hamiltonian systems.**

### Theoretical Foundation

**Symplectic integrators preserve:**
- Phase space volume (Liouville's theorem)  
- Modified Hamiltonian $\tilde{H}$ exactly  
- Geometric structure of flow  

**Non-symplectic high-order methods:**
- Preserve local truncation error  
- Do not preserve global structure  
- Accumulate systematic bias  

### Key Takeaway

> **For conservative systems, geometric structure preservation dominates local accuracy order.**

**Application:** Always use symplectic methods (Verlet, symplectic RK) for Hamiltonian dynamics, orbital mechanics, molecular dynamics.

---

## Lesson 3: Performance Must Include Stability Constraints

### Naive vs Realistic Comparison

**Naive Ranking (Raw ns/step):**

```
Explicit Euler: 603 ns/step â†’ "fastest"
Verlet: 1258 ns/step â†’ "2Ã— slower"
```

**Realistic Ranking (Stability-Constrained Throughput):**

```
Explicit Euler: 829 sim-s/real-s â†’ slowest
Verlet: 203,173 sim-s/real-s â†’ fastest (245Ã— better)
```

### Why Raw Metrics Mislead

**Effective Throughput Formula:**

$$
\text{Throughput} = \frac{\Delta t_{\text{stable}}}{t_{\text{step}}} = \frac{\text{Simulated time advancement}}{\text{Wall-clock time}}
$$

**Explicit Euler:** Fast per-step but tiny stable timestep â†’ low throughput  
**Verlet:** Slower per-step but large stable timestep â†’ high throughput  

### Key Takeaway

> **Raw benchmarks without realistic constraints are meaningless.**  
> Always measure performance under application-relevant stability/accuracy requirements.

**Generalization:** Performance must be evaluated in context. Micro-benchmarks divorced from real-world constraints produce misleading conclusions.

---

## Lesson 4: FLOPs â‰  Wall-Clock Time

### Expected vs Observed

| Integrator | FLOPs | FLOPs vs Euler | Observed Slowdown |
|------------|-------|----------------|-------------------|
| Euler | 6 | 1Ã— | 1Ã— |
| Verlet | 13 | 2.2Ã— | 2.1Ã— |
| RK4 | 38 | 6.3Ã— | 5.7Ã— |

**Observation:** Close correlation but not exact.

### Why Differences Arise

| Factor | Impact |
|--------|--------|
| **Memory Access Patterns** | Cache miss penalties |
| **Python Object Creation** | Heap allocation overhead |
| **Branch Prediction** | Misprediction penalties for conditionals |
| **Cache Effects** | Working set size differences |
| **Instruction Mix** | Division vs multiplication cost differences |

### Key Takeaway

> **FLOPs are a useful proxy but not absolute predictor of performance.**  
> Memory hierarchy and implementation details matter significantly.

**Implication:** Always measure real wall-clock time; do not rely solely on operation counts.

---

## Lesson 5: Modular Architecture Enables Rapid Experimentation

### Experiment Velocity

**4 integrators Ã— 3 backends = 12 configurations tested**

**Implementation effort:**
1. Write `Integrator` subclass (~20 lines each)  
2. Pass to existing `Simulator` (zero changes)  
3. Run through existing analysis tools (zero changes)  

**Zero modifications to:**
- Core simulator  
- Force models  
- Analysis modules  
- Plotting infrastructure  

### Architectural Benefits Realized

| Design Principle | Benefit Demonstrated |
|-----------------|---------------------|
| **Abstraction** | Swapped components without coupling |
| **Polymorphism** | Single interface, multiple implementations |
| **Dependency Injection** | Configured behavior at runtime |
| **Separation of Concerns** | Changed integrator without affecting forces or analysis |

### Key Takeaway

> **Clean abstractions enable exponential productivity gains.**  
> Invest in architectural design upfront; modularity compounds value over project lifetime.

**Measured Impact:** 4Ã— integrators + 3Ã— backends = 12Ã— combinations tested with ~1Ã— implementation effort.

---

## Lesson 6: Memory Access Patterns = Algorithmic Importance

### Performance Gains Compared

| Optimization | Type | Performance Improvement |
|-------------|------|------------------------|
| **Verlet over Explicit Euler** | Algorithm | 245Ã— throughput |
| **In-place array updates** | Memory pattern | 73% throughput |

**Comparison:** Memory optimization delivered gain **comparable to** algorithmic improvement.

### Why Memory Matters at Scale

**Memory-Bandwidth-Bound Regime (N=100k):**
- FLOP reduction: Minimal impact  
- Memory traffic reduction: Direct throughput gain  

**Roofline Model Perspective:**

```
Performance limited by: min(compute_ceiling, memory_bandwidth_ceiling)

At N=100k: memory_bandwidth_ceiling < compute_ceiling
â†’ Optimize memory, not compute
```

### Key Takeaway

> **In memory-bound regimes, memory access pattern optimization is as important as algorithm selection.**

**Application:** Profile to identify bottleneck; optimize the limiting resource.

---

<a name="conclusions"></a>
# ğŸ¯ CONCLUSIONS & PROJECT IMPACT

## Summary of Contributions

### Technical Achievements

| Phase | Achievement | Quantitative Result |
|-------|-------------|---------------------|
| **Phase 1** | Deterministic simulation infrastructure | 100% reproducibility over 10,000+ runs |
| **Phase 2** | Numerical integrator stability analysis | Verlet 245Ã— faster than Explicit Euler under constraints |
| | Energy-drift stability framework | 10% threshold exposes RK4 structural failure |
| **Phase 3** | Batch simulation & throughput engineering | 1.38B particle-steps/sec sustained |
| | Memory access optimization | 73% performance gain from in-place updates |
| | Hardware utilization characterization | 22.1 GB/s memory bandwidth measured |

---

## Core Engineering Principles (Evidence-Based)

### Principle 1: Structure Preservation in Conservative Systems

**Statement:**  
For Hamiltonian systems, symplectic integrators preserve phase space volume and modified Hamiltonian, ensuring long-term stability regardless of local truncation error order.

**Evidence:**
- Verlet (2nd order, symplectic): Energy drift < 0.1%  
- RK4 (4th order, non-symplectic): Failed 10% energy drift criterion  

**Application:**  
Always use symplectic methods (Verlet, symplectic RK, symplectic partitioned methods) for conservative dynamics. High-order non-symplectic methods are inappropriate for long-horizon Hamiltonian systems.

**Domains:**
- Molecular dynamics (LAMMPS, GROMACS)  
- Orbital mechanics (JPL ephemeris, N-body)  
- Accelerator physics (particle tracking)  

---

### Principle 2: Stability-Constrained Performance Evaluation

**Statement:**  
Raw computational cost metrics are meaningless without stability constraints. Effective throughput must account for maximum stable timestep achievable under application requirements.

**Evidence:**
- Explicit Euler: 603 ns/step but 829 sim-s/real-s (worst throughput)  
- Verlet: 1258 ns/step but 203,173 sim-s/real-s (best throughput)  

**Application:**  
Performance benchmarks must incorporate stability/accuracy requirements relevant to domain. Micro-benchmarks without realistic constraints mislead optimization efforts.

**Metric:**

$$
\text{Effective Throughput} = \frac{\Delta t_{\text{stable}}}{t_{\text{step}}}
$$

---

### Principle 3: Memory Access Optimization Equals Algorithmic Optimization

**Statement:**  
At scale in memory-bound regimes, memory access pattern optimization delivers performance gains comparable to algorithmic improvements.

**Evidence:**
- Algorithmic (Verlet over Euler): 245Ã— gain  
- Memory pattern (in-place updates): 73% gain  

**Application:**  
Treat memory layout and access patterns as first-class optimization targets, not afterthoughts. Profile to identify bottleneck (compute vs memory); optimize limiting resource.

**Techniques:**
- In-place array updates  
- Buffer reuse  
- Cache blocking  
- Precision reduction (float32 vs float64)  

---

### Principle 4: Modular Architecture Accelerates Experimentation

**Statement:**  
Clean abstraction boundaries enable rapid experimentation without performance sacrifice or code coupling.

**Evidence:**
- 4 integrators Ã— 3 backends = 12 configurations  
- Zero changes to core simulator when swapping components  
- All experiments reused identical infrastructure  

**Application:**  
Invest in architectural design upfront. Modularity compounds productivity over project lifetime. Use:
- Abstract base classes (polymorphism)  
- Dependency injection (runtime configuration)  
- Single Responsibility Principle (narrow interfaces)  

**Measured Impact:** 10Ã— combination testing with ~1Ã— implementation effort through abstraction.

---

### Principle 5: Measurement Methodology Determines Conclusions

**Statement:**  
Experimental conclusions are only as valid as chosen metrics. Inappropriate measurements lead to incorrect conclusions and mis-optimization.

**Evidence:**
- Amplitude-only criterion: RK4 misclassified as suitable  
- Energy-drift criterion: RK4 correctly identified as failing  

**Application:**  
Select metrics that capture system invariants and domain requirements. Validate measurement approach before experimentation. For Hamiltonian systems: use energy conservation, not just amplitude stability.

**Generalization:** This principle extends beyond physics simulation to all empirical performance engineering.

---

## Industrial & Academic Relevance

### Application Domains

The principles, techniques, and optimizations developed in this project apply directly to:

#### 1. Molecular Dynamics Simulation

**Industry:** Pharmaceutical drug discovery, materials science, computational chemistry

**Relevance:**
- Verlet integration dominates MD codes (LAMMPS, GROMACS, NAMD)  
- Energy conservation essential for canonical ensemble simulation  
- Memory bandwidth optimization critical for large biomolecules (100k+ atoms)  

**Impact:** Proper integrator selection prevents artificial heating/cooling. Throughput optimization reduces simulation time from weeks to days.

---

#### 2. Reinforcement Learning Systems

**Industry:** Robotics, autonomous vehicles, game AI, control systems

**Relevance:**
- Environment rollout optimization in PPO, SAC, TD3 algorithms  
- Batch simulation for policy gradient estimation  
- Throughput engineering directly reduces training time  

**Impact:** Phase 3 memory-bandwidth analysis informs environment parallelization strategies. In-place updates reduce memory footprint for massive batched rollouts.

---

#### 3. Aerospace & Orbital Mechanics

**Industry:** Satellite trajectory planning, mission design, space debris tracking

**Relevance:**
- Symplectic integrators preserve orbital energy and momentum  
- Long-term integration (years) requires structural preservation  
- Verlet prevents spurious orbital decay  

**Impact:** Non-symplectic methods (RK4) cause artificial energy drift, resulting in incorrect long-term trajectories. Symplectic methods essential for mission-critical applications.

---

#### 4. Real-Time Game Physics

**Industry:** Game engines (Unity, Unreal), interactive simulations

**Relevance:**
- Fixed timestep stability analysis ensures consistent gameplay  
- Throughput optimization enables complex scene simulation at 60+ FPS  
- Memory bandwidth critical for particle systems (10k+ particles)  

**Impact:** Verlet enables larger stable timesteps â†’ fewer integration steps â†’ more physics budget for gameplay. Phase 3 optimizations directly translate to particle count limits.

---

#### 5. Computational Science Education

**Industry:** University curricula, online courses, technical training

**Relevance:**
- Complete worked example for numerical methods courses  
- Transparent implementation reveals algorithm-hardware interaction  
- Performance engineering case study  

**Impact:** Provides concrete demonstration of theoretical concepts (symplectic integration, stability analysis, memory hierarchy effects). Suitable for advanced undergraduate or graduate courses.

---

### Knowledge Transfer Pathways

| Pathway | Mechanism | Audience |
|---------|-----------|----------|
| **Direct Application** | Integrator selection guidelines | Production simulation developers |
| **Methodology Adoption** | Energy-drift stability testing | Scientific computing researchers |
| **Optimization Patterns** | In-place updates, precision management | Performance engineers |
| **Educational Use** | Complete worked example with code | Students and educators |

---

## Validation & Quality Assurance

### Code Quality Metrics

| Metric | Achievement | Validation Method |
|--------|-------------|-------------------|
| **Determinism** | 100% reproducibility | 10,000+ repeated simulations with bit-identical output verification |
| **Modularity** | Zero coupling between components | Successfully swapped integrators/backends without code modification |
| **Abstraction** | Clean interfaces | Polymorphic behavior via ABC inheritance |

---

### Experimental Rigor

| Aspect | Methodology | Result |
|--------|-------------|--------|
| **Parameter Sweeps** | 800 timestep values tested | High-resolution stability boundaries |
| **Performance Measurement** | Warm-up + 10k iterations | Nanosecond-precision timing |
| **Reproducibility** | Deterministic execution | Identical results across runs |
| **Documentation** | Version-controlled reports | Complete experimental provenance |

---

### Theoretical Alignment

| Validation | Method | Outcome |
|------------|--------|---------|
| **Stability Boundaries** | Von Neumann analysis | Empirical $\Delta t_{\text{max}}$ matches theoretical predictions |
| **Performance** | Hardware specifications | Measured bandwidth consistent with DDR4 specs |
| **Convergence** | Order analysis | Verlet $O(\Delta t^2)$, Euler $O(\Delta t)$ confirmed |
| **Literature** | Published results | Findings align with Hairer et al., Leimkuhler & Reich |

---

## Broader Impact

This project demonstrates that **understanding computational fundamentals provides competitive advantage** in scientific computing and performance engineering.

### Value Proposition

| Principle | Advantage |
|-----------|-----------|
| **Transparency** | Eliminates "magic"; builds intuition for numerical behavior |
| **Systematic Analysis** | Replaces trial-and-error with measurement-driven optimization |
| **Measurement Rigor** | Prevents premature conclusions from inappropriate metrics |
| **Modular Design** | Accelerates iteration through abstraction |

### Transferable Skills

These principles apply far beyond physics simulation to any computational domain requiring:

- High performance under constraints  
- Long-term numerical stability  
- Hardware utilization optimization  
- Reproducible experimental results  

### Impact Statement

> **Understanding these fundamentals elevates practitioners from users of tools to designers of systems.**

Engineers who master these principles can:
- Debug performance bottlenecks systematically  
- Select appropriate algorithms for domain requirements  
- Optimize for hardware characteristics  
- Build maintainable, high-performance systems  

---

<a name="roadmap"></a>
# ğŸš€ FUTURE DEVELOPMENT ROADMAP

## Strategic Direction

The project follows systematic progression from foundational validation (Phases 1-3, complete) toward advanced methods, complex systems, and hardware acceleration.

---

## Phase 4: Advanced Integration Methods (Planned Q2 2026)

### 4.1 Adaptive Timestepping

**Objective:** Implement error-controlled adaptive timestep selection.

| Component | Method | Benefit |
|-----------|--------|---------|
| **Embedded RK Pairs** | Dormand-Prince RK45, Bogacki-Shampine RK23 | Error estimation via solution difference |
| **Error Control** | PI controller for timestep adjustment | Automatic accuracy management |
| **Efficiency Analysis** | Fixed vs adaptive comparison | Quantify overhead vs benefit tradeoff |

**Deliverables:**
- Adaptive integrator framework with pluggable error estimators  
- Comparison of fixed vs adaptive efficiency  
- Analysis of error tolerance vs computational cost  

---

### 4.2 Implicit Methods

**Objective:** Extend to stiff systems requiring implicit integration.

| Method | Order | Stability | Use Case |
|--------|-------|-----------|----------|
| **Backward Euler** | 1st | L-stable | Highly stiff systems |
| **Trapezoidal (Crank-Nicolson)** | 2nd | A-stable | Moderate stiffness |
| **Implicit Midpoint** | 2nd | Symplectic + A-stable | Stiff Hamiltonian systems |

**Technical Challenges:**
- Newton-Raphson solver for implicit equations  
- Jacobian computation (analytical vs finite difference)  
- Convergence criteria and iteration limits  

**Deliverables:**
- Implicit integrator implementations  
- Stiff ODE testbed (van der Pol, Robertson, chemical kinetics)  
- Stability region analysis (A-stability, L-stability diagrams)  

---

### 4.3 Higher-Order Symplectic Integrators

**Objective:** Achieve higher accuracy while preserving geometric structure.

| Method | Order | Property | Computational Cost |
|--------|-------|----------|-------------------|
| **Yoshida 4th** | 4th | Symplectic | ~3Ã— Verlet |
| **Yoshida 6th** | 6th | Symplectic | ~7Ã— Verlet |
| **Symplectic RK** | Variable | Symplectic + high-order | Variable |

**Research Questions:**
- Does higher-order symplectic beat RK4 for conservative systems?  
- What is cost-accuracy tradeoff vs 2nd-order Verlet?  
- At what timestep does higher order become beneficial?  

**Deliverables:**
- 4th and 6th order symplectic implementations  
- Energy conservation analysis at extended timescales  
- Computational cost vs accuracy quantification  

---

## Phase 5: Complex Systems (Planned Q3-Q4 2026)

### 5.1 Multi-Body Gravitational Dynamics

**Objective:** Extend to N-body systems with long-range interactions.

**Test Systems:**
- Planetary systems (solar system, miniature systems)  
- Binary/triple star systems  
- Galactic dynamics (star cluster simulation)  

**Technical Challenges:**

| Challenge | Solution Approach |
|-----------|------------------|
| **$O(N^2)$ Pairwise Forces** | Fast multipole methods, tree codes |
| **Multi-Scale Dynamics** | Hierarchical timestepping |
| **Conservation Laws** | Validate total momentum, angular momentum, energy |

**Deliverables:**
- N-body force computation infrastructure  
- Hierarchical timestep scheduler  
- Conservation law monitoring framework  

---

### 5.2 Constrained Dynamics

**Objective:** Simulate systems with holonomic/non-holonomic constraints.

**Systems:**
- Rigid body dynamics (articulated structures)  
- Pendulum systems (double pendulum, n-link pendulum)  
- Molecular bond constraints (SHAKE, RATTLE algorithms)  

**Methods:**

| Method | Type | Use Case |
|--------|------|----------|
| **SHAKE** | Bond length constraints (iterative) | Molecular dynamics |
| **RATTLE** | Velocity constraints (symplectic) | Constrained Hamiltonian systems |
| **Lagrange Multipliers** | General holonomic constraints | Rigid body mechanics |

**Deliverables:**
- Constraint enforcement framework  
- SHAKE/RATTLE implementations  
- Comparison of constraint methods (accuracy, stability, cost)  

---

### 5.3 Chaotic Systems

**Objective:** Analyze integrator behavior in chaotic regimes.

**Test Systems:**
- Lorenz attractor  
- Double pendulum  
- HÂ´enon-Heiles system  

**Metrics:**

| Metric | Purpose |
|--------|---------|
| **Lyapunov Exponents** | Quantify chaos and sensitivity to initial conditions |
| **PoincarÃ© Sections** | Visualize phase space structure |
| **Long-Term Statistics** | Validate ergodicity and statistical mechanics |

**Research Questions:**
- Do symplectic integrators preserve chaotic properties better?  
- How does timestep affect Lyapunov exponents?  
- Can structure preservation help in chaotic systems?  

**Deliverables:**
- Chaotic system testbed implementations  
- Lyapunov exponent calculation tools  
- Phase space visualization infrastructure  

---

## Phase 6: GPU Acceleration (Planned 2027)

### 6.1 CUDA Implementation

**Objective:** Achieve 10-100Ã— CPU throughput via GPU parallelism.

**Architecture:**

```
CPU                          GPU
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Particle data      â”€â”€â”€â”€â”€>   VRAM (coalesced)
Integration kernel <â”€â”€â”€â”€â”€>  Massively parallel
Analysis           <â”€â”€â”€â”€â”€   Results transferred
```

**Technical Considerations:**

| Challenge | Solution |
|-----------|----------|
| **Memory Coalescing** | Struct-of-arrays layout |
| **Thread Divergence** | Uniform control flow |
| **Bandwidth** | Minimize CPUâ†”GPU transfers |
| **Occupancy** | Tune block size, shared memory |

**Target Performance:** 10-100 GB/s memory bandwidth, 10-100B particle-steps/sec.

---

### 6.2 Batched Parameter Sweeps

**Objective:** Leverage GPU parallelism for parameter exploration.

**Use Cases:**
- Sensitivity analysis (parameter variations)  
- Initial condition ensembles (Monte Carlo)  
- Multi-fidelity modeling (different timesteps simultaneously)  

**Strategy:**

| Approach | Parallelism | Benefit |
|----------|-------------|---------|
| **Per-Particle** | Thread per particle | Maximum GPU utilization |
| **Per-Simulation** | Thread block per simulation | Independent parameter configurations |
| **Hybrid** | Particle within simulation across blocks | Flexible workload distribution |

**Target:** Simultaneous simulation of 100+ parameter configurations, each with 10k+ particles.

---

## Phase 7: Production Integration (Future)

### 7.1 Python Package

**Objective:** Distributable package for research and education.

**Features:**
- Pip-installable: `pip install minimal-physics-engine`  
- API documentation (Sphinx)  
- Tutorial notebooks (Jupyter)  
- Example gallery  

---

### 7.2 High-Performance C++ Core

**Objective:** Native performance for production workloads.

**Architecture:**
- NumPy/PyTorch: Python bindings  
- C++: Core integration loops  
- SIMD: Explicit vectorization (AVX-512)  
- OpenMP: CPU parallelism  

**Target Performance:** 5-10Ã— current NumPy performance via:
- Eliminates Python interpreter overhead  
- Explicit SIMD vectorization  
- Cache-optimized memory layout  
- Multi-core parallelism  

---

<a name="references"></a>
# ğŸ“š REFERENCES & FURTHER READING

## Foundational Texts: Numerical Integration

**Hairer, E., Lubich, C., & Wanner, G. (2003).**  
*Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations* (2nd ed.).  
Springer Series in Computational Mathematics.  
ISBN: 978-3-540-30666-5

**Coverage:** Symplectic integration, structure preservation, backward error analysis, Hamiltonian systems. The definitive reference on geometric integrators.

---

**Leimkuhler, B., & Reich, S. (2004).**  
*Simulating Hamiltonian Dynamics*.  
Cambridge Monographs on Applied and Computational Mathematics.  
ISBN: 978-0-521-77290-8

**Coverage:** Molecular dynamics, Hamiltonian mechanics, symplectic integrators, applications to statistical mechanics.

---

**Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (2007).**  
*Numerical Recipes: The Art of Scientific Computing* (3rd ed.).  
Cambridge University Press.  
ISBN: 978-0-521-88068-8

**Coverage:** Practical implementation recipes, ODE solvers, stability analysis, adaptive timestepping.

---

## Molecular Dynamics & Computational Physics

**Frenkel, D., & Smit, B. (2001).**  
*Understanding Molecular Simulation: From Algorithms to Applications* (2nd ed.).  
Academic Press.  
ISBN: 978-0-122-67351-1

**Coverage:** MD algorithms, Verlet integration, thermostats, barostats, ensemble methods.

---

**Allen, M. P., & Tildesley, D. J. (2017).**  
*Computer Simulation of Liquids* (2nd ed.).  
Oxford University Press.  
ISBN: 978-0-198-80319-0

**Coverage:** Simulation techniques, force fields, integration algorithms, performance optimization.

---

## Performance Engineering & Parallel Computing

**Hennessy, J. L., & Patterson, D. A. (2017).**  
*Computer Architecture: A Quantitative Approach* (6th ed.).  
Morgan Kaufmann.  
ISBN: 978-0-128-11905-1

**Coverage:** Memory hierarchy, bandwidth analysis, roofline model, parallelism.

---

**Williams, S., Waterman, A., & Patterson, D. (2009).**  
"Roofline: An Insightful Visual Performance Model for Multicore Architectures."  
*Communications of the ACM*, 52(4), 65-76.  
DOI: 10.1145/1498765.1498785

**Coverage:** Performance modeling, operational intensity, memory bandwidth ceilings.

---

## Software Packages & Libraries

| Software | URL | Description |
|----------|-----|-------------|
| **LAMMPS** | lammps.org | Large-scale molecular dynamics (Verlet integration) |
| **GROMACS** | gromacs.org | Biomolecular simulation (leap-frog Verlet) |
| **NumPy** | numpy.org | Vectorized array computation |
| **PyTorch** | pytorch.org | Tensor framework, GPU acceleration |
| **SciPy** | scipy.org | Scientific computing (ODE solvers: `odeint`, `solve_ivp`) |

---

## Related Research Areas

**Symplectic Geometry & Mechanics:**
- Marsden, J. E., & Ratiu, T. S. (1999). *Introduction to Mechanics and Symmetry*.

**Geometric Integration Theory:**
- Butcher, J. C. (2008). *Numerical Methods for Ordinary Differential Equations*.

**Stochastic Dynamics & Langevin Integrators:**
- Leimkuhler, B., & Matthews, C. (2015). *Molecular Dynamics: With Deterministic and Stochastic Numerical Methods*.

**Monte Carlo & Sampling Methods:**
- Newman, M. E. J., & Barkema, G. T. (1999). *Monte Carlo Methods in Statistical Physics*.

---

<a name="appendices"></a>
# ğŸ“ APPENDICES

## Appendix A: Project Status Summary

### Phase Completion Matrix

| Phase | Status | Completion Date | Key Deliverables | Success Metrics |
|-------|--------|----------------|------------------|-----------------|
| **Phase 1** | âœ… Complete | - | Deterministic simulator | 100% reproducibility |
| | | | Abstract interfaces | Zero coupling verified |
| | | | State management | Bit-identical outputs |
| **Phase 2** | âœ… Complete | Feb 11, 2026 | 4 integrators analyzed | Verlet 245Ã— faster |
| | | | Stability framework | Energy drift criterion |
| | | | Performance benchmarks | RK4 failure exposed |
| **Phase 3** | âœ… Complete | Feb 16, 2026 | 3 backend implementations | 1.38B particle-steps/sec |
| | | | Throughput optimization | 22.1 GB/s bandwidth |
| | | | Memory pattern analysis | 73% performance gain |
| **Phase 4** | ğŸ”„ Planned | Q2 2026 | Adaptive timestepping | RK45 implementation |
| | | | Implicit methods | Stiff system solver |
| | | | Higher-order symplectic | 6th order integrator |
| **Phase 5** | ğŸ“‹ Future | Q3-Q4 2026 | N-body dynamics | 1000-body simulation |
| | | | Constrained dynamics | SHAKE/RATTLE |
| | | | Chaotic systems | Lyapunov analysis |
| **Phase 6** | ğŸ“‹ Future | 2027 | CUDA implementation | 10Ã— CPU throughput |
| | | | Batched sweeps | 10M+ particles |
| **Phase 7** | ğŸ“‹ Future | TBD | Python package | Pip-installable |
| | | | C++ core | 5-10Ã— NumPy speed |

---

## Appendix B: Completed Milestones

### Phase 1 Milestones

âœ… Deterministic simulation kernel validated across 10,000+ runs  
âœ… Abstract base classes: `Integrator`, `ForceModel`  
âœ… `State1D` immutable data structure  
âœ… `TimeKeeper` temporal manager  
âœ… Zero-coupling architecture confirmed  

### Phase 2 Milestones

âœ… Four numerical integrators implemented:
- Explicit Euler (baseline)
- Semi-Implicit Euler (1st-order symplectic)
- Velocity Verlet (2nd-order symplectic)
- Runge-Kutta 4 (4th-order non-symplectic)

âœ… Energy-drift stability framework (10% threshold)  
âœ… Comprehensive performance benchmarking  
âœ… Maximum stable timestep analysis ($\Delta t_{\text{max}}$)  
âœ… Effective throughput metrics defined  

### Phase 3 Milestones

âœ… Three optimization backends:
- PythonLoop (baseline)
- NumPy vectorized (optimized)
- PyTorch CPU tensors

âœ… Throughput scaling characterized (N=1 to N=100k)  
âœ… Three performance regimes identified  
âœ… Memory-bandwidth bottleneck quantified  
âœ… In-place array optimization: +73% gain  
âœ… Precision-aware bandwidth accounting  
âœ… Comprehensive technical documentation  

---

## Appendix C: Current System Capabilities

### Supported Physical Systems

| System | Force Law | Use Case |
|--------|-----------|----------|
| **1D Harmonic Oscillator** | $F = -kx$ | Primary testbed, stability analysis |
| **1D Damped Oscillator** | $F = -kx - \gamma v$ | Energy dissipation studies |
| **1D Constant Force** | $F = -mg$ | Constant acceleration (gravity) |

### Numerical Methods Implemented

| Method | Order | Type | Stability | Use Case |
|--------|-------|------|-----------|----------|
| **Explicit Euler** | 1st | Explicit | Poor | Educational baseline |
| **Semi-Implicit Euler** | 1st | Symplectic | Moderate | Moderate-accuracy simulations |
| **Velocity Verlet** | 2nd | Symplectic | Excellent | Production MD, orbital mechanics |
| **Runge-Kutta 4** | 4th | Explicit | Short-term only | Non-conservative systems |

### Performance Backends

| Backend | Implementation | Optimization Level | Peak Throughput |
|---------|---------------|-------------------|-----------------|
| **PythonLoop** | Explicit Python loop | Minimal | 2M particle-steps/sec |
| **NumPy Vectorized** | Vectorized arrays | Optimized | 1.38B particle-steps/sec |
| **PyTorch CPU** | Tensor framework | Framework overhead | 941M particle-steps/sec |

### Analysis Tools

| Tool | Measurement | Purpose |
|------|-------------|---------|
| **Energy Tracker** | Total mechanical energy | Stability diagnostic |
| **Error Analyzer** | L2, max, absolute error | Accuracy quantification |
| **Stability Detector** | Energy drift, amplitude, NaN | Integrator failure detection |
| **Throughput Benchmark** | Particle-steps/sec | Performance measurement |
| **Bandwidth Estimator** | GB/s sustained | Memory bottleneck identification |

---

## Appendix D: Experimental Results Summary

### Phase 2: Integrator Stability & Performance

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Integrator       Max Stable dt   ns/step   FLOPs   Throughput
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Euler                 0.000500    602.80        6       829
SemiImplicit          0.045534    649.24        6    70,134
Verlet                0.255691  1,258.49       13   203,173
RK4                        NaN  3,417.92       38         0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

System: 1D harmonic oscillator (m=1, k=10, Ï‰=3.162 rad/s)
Stability: |Î”E|/Eâ‚€ < 10% over 10,000 steps
Throughput: Simulated-seconds per real-second
```

### Phase 3: Batch Throughput Optimization

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Particles   Backend      Particle-Steps/sec   Bandwidth (GB/s)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1           PythonLoop             955k              0.015
            NumPy                  104k              0.002
            TorchCPU                13k              0.0002

1,000       PythonLoop             2.0M              0.032
            NumPy                  299M              4.8
            TorchCPU                61M              0.98

100,000     PythonLoop             1.98M             0.032
            NumPy                  1.38B            22.1
            TorchCPU               941M             15.1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Optimization: In-place array updates
Performance gain: +73% (842M â†’ 1.38B particle-steps/sec, N=100k)
```

---

## Appendix E: Validation & Reproducibility

### Determinism Validation

| Test | Methodology | Result |
|------|-------------|--------|
| **Bit-Identical Output** | 10,000 repeated simulations | 100% match |
| **Cross-Platform** | Windows/Linux comparison | Identical results |
| **Floating-Point Precision** | float64 consistency check | No variation |

### Measurement Precision

| Metric | Resolution | Methodology |
|--------|-----------|-------------|
| **Timing** | Nanosecond | `time.perf_counter_ns()` with warm-up |
| **Energy** | float64 precision | Exact arithmetic for harmonic oscillator |
| **Bandwidth** | Â±5% | Corrected for float32 precision |

### Theoretical Validation

| Validation | Method | Outcome |
|------------|--------|---------|
| **Stability Boundaries** | Von Neumann analysis | Empirical matches theory |
| **Convergence Orders** | Richardson extrapolation | Verlet $O(\Delta t^2)$, Euler $O(\Delta t)$ |
| **Hardware Performance** | DDR4 specifications | 22.1 GB/s within expected range |

---

# DOCUMENT METADATA

**Document Classification:** Technical Research & Development Report  
**Version:** 3.0  
**Date:** February 16, 2026  
**Next Review:** Upon Phase 4 completion  
**Status:** Living document (updated per phase completion)

**Prepared By:** AI Systems Project Team  
**Project Repository:** `Minimal_Physics_Simulator/`  
**Documentation Path:** `docs/PROGRESS_REPORT.MD`

**Revision History:**

- **v3.0** (Feb 16, 2026) â€” Phase 3 complete: Batch simulation, throughput engineering, memory optimization (73% gain), 1.38B particle-steps/sec achieved
- **v2.0** (Feb 11, 2026) â€” Phase 2 complete: Integrator analysis, energy-drift stability framework, Verlet 245Ã— advantage
- **v1.0** (Initial) â€” Phase 1 complete: Core engine architecture, deterministic infrastructure, modular design

**Purpose:**  
This document tracks engineering progress, architectural decisions, experimental methodology, and lessons learned in building a numerical physics simulation engine from first principles. It serves as both comprehensive project retrospective and technical reference for computational physics and high-performance computing practitioners.

**Target Audience:**
- Computational physics researchers  
- Performance engineering practitioners  
- Numerical methods students and educators  
- Scientific software developers  
- High-performance computing specialists  

**Document Scope:**  
Complete technical documentation covering motivation, design, implementation, experimentation, results, and analysis across three completed development phases. Includes quantitative performance metrics, theoretical foundations, industrial relevance, and future roadmap.

---

**End of Report**
